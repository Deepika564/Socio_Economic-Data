{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjVSC0ZoNc9nUjuTrHWIP5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import files\n","\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"Fh0Y-8YfasFq","executionInfo":{"status":"ok","timestamp":1749954536090,"user_tz":240,"elapsed":18348,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"24bdee04-9b1a-401a-b2ba-f5264a9c2f1b"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-1665e848-c1ec-46c4-a4b3-dc9cc32196b7\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-1665e848-c1ec-46c4-a4b3-dc9cc32196b7\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Test (1).csv to Test (1).csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Assuming 'Test (1).csv' was one of the uploaded files\n","try:\n","    df = pd.read_csv('Test (1).csv')\n","    print(df.columns)\n","except FileNotFoundError:\n","    print(\"The file 'Test (1).csv' was not found. Please ensure it was uploaded correctly.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcBMyuOKa4B8","executionInfo":{"status":"ok","timestamp":1749954562438,"user_tz":240,"elapsed":11,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"c18c0f59-c6e3-480b-df80-fce379fbe790"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n","       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["# Check for missing values\n","print(df.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v9J6a_Xwa85N","executionInfo":{"status":"ok","timestamp":1749954582293,"user_tz":240,"elapsed":40,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"9faca230-735d-475d-dd5e-30f38d01f507"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ID                   0\n","Gender               0\n","Ever_Married        50\n","Age                  0\n","Graduated           24\n","Profession          38\n","Work_Experience    269\n","Spending_Score       0\n","Family_Size        113\n","Var_1               32\n","dtype: int64\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Assuming df is already loaded from 'Test (1).csv'\n","\n","# 1. Display the first few rows\n","print(\"First 5 rows of the DataFrame:\")\n","print(df.head())\n","\n","# 2. Get column data types and non-null counts\n","print(\"\\nData types and non-null counts:\")\n","print(df.info())\n","\n","# 3. Get descriptive statistics for numerical columns\n","print(\"\\nDescriptive statistics for numerical columns:\")\n","print(df.describe())\n","\n","# 4. Check the shape of the DataFrame\n","print(\"\\nShape of the DataFrame (rows, columns):\")\n","print(df.shape)\n","\n","# 5. Get unique values and their counts for a sample categorical column\n","# You would need to identify a categorical column in your data first.\n","# Let's assume 'example_categorical_column' is a categorical column in your data.\n","# Replace 'example_categorical_column' with an actual column name from df.columns\n","# try:\n","#     print(\"\\nValue counts for 'example_categorical_column':\")\n","#     print(df['example_categorical_column'].value_counts())\n","# except KeyError:\n","#     print(\"\\n'example_categorical_column' not found. Please replace with a valid categorical column name.\")\n","\n","# You can repeat step 5 for other categorical columns as needed."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGOViSHCbHeM","executionInfo":{"status":"ok","timestamp":1749954630498,"user_tz":240,"elapsed":73,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"68a48d99-5b06-4076-aed6-16dad1016501"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 rows of the DataFrame:\n","       ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n","0  458989  Female          Yes   36       Yes    Engineer              0.0   \n","1  458994    Male          Yes   37       Yes  Healthcare              8.0   \n","2  458996  Female          Yes   69        No         NaN              0.0   \n","3  459000    Male          Yes   59        No   Executive             11.0   \n","4  459001  Female           No   19        No   Marketing              NaN   \n","\n","  Spending_Score  Family_Size  Var_1  \n","0            Low          1.0  Cat_6  \n","1        Average          4.0  Cat_6  \n","2            Low          1.0  Cat_6  \n","3           High          2.0  Cat_6  \n","4            Low          4.0  Cat_6  \n","\n","Data types and non-null counts:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2627 entries, 0 to 2626\n","Data columns (total 10 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   ID               2627 non-null   int64  \n"," 1   Gender           2627 non-null   object \n"," 2   Ever_Married     2577 non-null   object \n"," 3   Age              2627 non-null   int64  \n"," 4   Graduated        2603 non-null   object \n"," 5   Profession       2589 non-null   object \n"," 6   Work_Experience  2358 non-null   float64\n"," 7   Spending_Score   2627 non-null   object \n"," 8   Family_Size      2514 non-null   float64\n"," 9   Var_1            2595 non-null   object \n","dtypes: float64(2), int64(2), object(6)\n","memory usage: 205.4+ KB\n","None\n","\n","Descriptive statistics for numerical columns:\n","                  ID          Age  Work_Experience  Family_Size\n","count    2627.000000  2627.000000      2358.000000  2514.000000\n","mean   463433.918919    43.649791         2.552587     2.825378\n","std      2618.245698    16.967015         3.341094     1.551906\n","min    458989.000000    18.000000         0.000000     1.000000\n","25%    461162.500000    30.000000         0.000000     2.000000\n","50%    463379.000000    41.000000         1.000000     2.000000\n","75%    465696.000000    53.000000         4.000000     4.000000\n","max    467968.000000    89.000000        14.000000     9.000000\n","\n","Shape of the DataFrame (rows, columns):\n","(2627, 10)\n"]}]},{"cell_type":"code","source":["target_column_name = 'your_target_column' # e.g., 'Result', 'Outcome'\n","feature_column_names = ['feature1', 'feature2', 'feature3'] # e.g., ['Age', 'Salary', 'Experience']"],"metadata":{"id":"j_FjhJ_7boou","executionInfo":{"status":"ok","timestamp":1749954765725,"user_tz":240,"elapsed":12,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["target_column_name = 'Outcome'\n","feature_column_names = ['Age', 'Salary']"],"metadata":{"id":"gP6kJBM0btoc","executionInfo":{"status":"ok","timestamp":1749954783313,"user_tz":240,"elapsed":5,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","import pandas as pd\n","\n","# Use the column names you've specified\n","target_column_name = 'Outcome'\n","feature_column_names = ['Age', 'Salary']\n","\n","# Assuming df is already loaded from 'Test (1).csv' and is available\n","\n","try:\n","    # 1. Identify Features (X) and Target Variable (y)\n","    # Select the columns using the specified names\n","    X = df[feature_column_names]\n","    y = df[target_column_name]\n","\n","    # --- Optional: Handle Categorical Features ---\n","    # If 'Age' or 'Salary' are categorical (which is unlikely for these names),\n","    # you would need encoding here. Assuming they are numeric for this example.\n","    # If you had other categorical features in feature_column_names:\n","    # X = pd.get_dummies(X, columns=['name_of_categorical_column'])\n","\n","    # --- Optional: Handle Missing Values ---\n","    # Based on your earlier check, if there were missing values in 'Age',\n","    # 'Salary', or 'Outcome', you need to handle them before splitting.\n","    # Example: Drop rows with missing values in these columns\n","    # df.dropna(subset=feature_column_names + [target_column_name], inplace=True)\n","    # After dropping, you'd need to re-select X and y from the modified df.\n","\n","    # 3. Split the Data into Training and Testing Sets\n","    # Split 80% for training and 20% for testing\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n","    print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n","\n","    # 4. Instantiate and Train the Model\n","    model = LogisticRegression()\n","\n","    # Fit the model to the training data\n","    model.fit(X_train, y_train)\n","\n","    print(\"\\nLogistic Regression model trained successfully.\")\n","\n","    # 5. Make Predictions and Evaluate\n","    y_pred = model.predict(X_test)\n","\n","    print(\"\\nModel Evaluation on the Test Set:\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","except KeyError as e:\n","    print(f\"Error: One of the specified column names ('Outcome', 'Age', 'Salary') was not found in the DataFrame. Please check the column names in your 'Test (1).csv' file. {e}\")\n","except ValueError as e:\n","     print(f\"Error: Check the data in 'Age', 'Salary', and 'Outcome' columns. Ensure 'Outcome' is binary and features are numeric or correctly encoded. {e}\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiIBeY4UbzLk","executionInfo":{"status":"ok","timestamp":1749954805407,"user_tz":240,"elapsed":38,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"38e494f1-411a-4e27-8538-057501cfc973"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: One of the specified column names ('Outcome', 'Age', 'Salary') was not found in the DataFrame. Please check the column names in your 'Test (1).csv' file. \"['Salary'] not in index\"\n"]}]},{"cell_type":"code","source":["feature_column_names = ['Age', 'Salary']"],"metadata":{"id":"lP4V1cZCb8W8","executionInfo":{"status":"ok","timestamp":1749954842319,"user_tz":240,"elapsed":36,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["feature_column_names = ['Age', 'EmployeeSalary']"],"metadata":{"id":"FS8o1JoHb-C4","executionInfo":{"status":"ok","timestamp":1749954849806,"user_tz":240,"elapsed":17,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print(df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NV0bpoRAcCt-","executionInfo":{"status":"ok","timestamp":1749954867943,"user_tz":240,"elapsed":31,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"a2937f96-17dc-4867-a3d4-7b0d74162f96"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n","       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["target_column_name = 'Graduated'\n","feature_column_names = ['Age', 'Work_Experience']"],"metadata":{"id":"hN2S-ProcIkR","executionInfo":{"status":"ok","timestamp":1749954892520,"user_tz":240,"elapsed":47,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","import pandas as pd\n","\n","# --- Specify your target and feature column names ---\n","target_column_name = 'Graduated'\n","feature_column_names = ['Age', 'Work_Experience', 'Gender'] # Added 'Gender'\n","# ----------------------------------------------------\n","\n","# Assuming df is already loaded\n","\n","try:\n","    # 1. Identify Features (X) and Target Variable (y)\n","    X = df[feature_column_names]\n","    y = df[target_column_name]\n","\n","    # --- Handle Categorical Features ---\n","    # Use one-hot encoding for the 'Gender' column\n","    X = pd.get_dummies(X, columns=['Gender'], drop_first=True) # drop_first=True avoids multicollinearity\n","\n","    print(\"Features after encoding:\")\n","    print(X.head()) # Check the transformed features\n","    print(X.columns) # Check the new column names after encoding\n","\n","    # --- Handle Missing Values (if any in selected columns) ---\n","    # Check again for missing values specifically in the selected columns\n","    # print(\"\\nMissing values in selected features and target:\")\n","    # print(df[feature_column_names + [target_column_name]].isnull().sum())\n","    # If missing values exist, handle them before splitting.\n","    # For example, dropping rows with any missing values in the selected columns:\n","    # df_cleaned = df[feature_column_names + [target_column_name]].dropna()\n","    # If dropping rows, you'd need to redefine X and y from df_cleaned:\n","    # X = df_cleaned[feature_column_names]\n","    # y = df_cleaned[target_column_name]\n","    # X = pd.get_dummies(X, columns=['Gender'], drop_first=True) # Re-encode after dropping\n","\n","    # 3. Split the Data into Training and Testing Sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    print(f\"\\nTraining set shape: {X_train.shape}, {y_train.shape}\")\n","    print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n","\n","    # 4. Instantiate and Train the Model\n","    model = LogisticRegression()\n","\n","    # Fit the model to the training data\n","    model.fit(X_train, y_train)\n","\n","    print(\"\\nLogistic Regression model trained successfully.\")\n","\n","    # 5. Make Predictions and Evaluate\n","    y_pred = model.predict(X_test)\n","\n","    print(\"\\nModel Evaluation on the Test Set:\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","except KeyError as e:\n","    print(f\"Error: One of the specified column names was not found in the DataFrame. Please check 'target_column_name' and 'feature_column_names'. {e}\")\n","except ValueError as e:\n","     print(f\"Error: Check the data in your selected columns. Ensure your target is binary and features are numeric or correctly encoded. {e}\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNhGftW-cSZb","executionInfo":{"status":"ok","timestamp":1749954933413,"user_tz":240,"elapsed":211,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"ed7473bc-7df3-44fb-fd95-1f7822fa4f0a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Features after encoding:\n","   Age  Work_Experience  Gender_Male\n","0   36              0.0        False\n","1   37              8.0         True\n","2   69              0.0        False\n","3   59             11.0         True\n","4   19              NaN        False\n","Index(['Age', 'Work_Experience', 'Gender_Male'], dtype='object')\n","\n","Training set shape: (2101, 3), (2101,)\n","Testing set shape: (526, 3), (526,)\n","Error: Check the data in your selected columns. Ensure your target is binary and features are numeric or correctly encoded. Input X contains NaN.\n","LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","import pandas as pd\n","\n","# --- Specify your target and feature column names ---\n","target_column_name = 'Graduated'\n","feature_column_names = ['Age', 'Work_Experience', 'Gender'] # Added 'Gender'\n","# ----------------------------------------------------\n","\n","# Assuming df is already loaded\n","\n","try:\n","    # 1. Identify Features (X) and Target Variable (y)\n","    X = df[feature_column_names]\n","    y = df[target_column_name]\n","\n","    # --- Handle Categorical Features ---\n","    # Use one-hot encoding for the 'Gender' column\n","    # drop_first=True avoids multicollinearity by dropping one of the binary columns\n","    X = pd.get_dummies(X, columns=['Gender'], drop_first=True)\n","\n","    print(\"Features after encoding:\")\n","    print(X.head()) # Check the transformed features\n","    print(X.columns) # Check the new column names after encoding\n","\n","    # --- Handle Missing Values (if any in selected columns) ---\n","    # It's good practice to handle missing values before splitting.\n","    # Based on your earlier check, if there were missing values,\n","    # uncomment and adapt one of the following methods:\n","\n","    # Option 1: Drop rows with any missing values in the selected columns\n","    # print(\"\\nMissing values before handling (selected columns):\")\n","    # print(df[feature_column_names + [target_column_name]].isnull().sum())\n","    # df_cleaned = df[feature_column_names + [target_column_name]].dropna()\n","    # If dropping rows, you'd need to redefine X and y from df_cleaned:\n","    # X = df_cleaned[feature_column_names]\n","    # y = df_cleaned[target_column_name]\n","    # X = pd.get_dummies(X, columns=['Gender'], drop_first=True) # Re-encode after dropping\n","\n","    # Option 2: Impute missing values (e.g., with the mean for numerical columns)\n","    # For numerical columns in X:\n","    # for col in ['Age', 'Work_Experience']: # Add other numerical features here\n","    #     if col in X.columns: # Check if the column exists after get_dummies if needed\n","    #         X[col].fillna(X[col].mean(), inplace=True)\n","    # For the target variable (if numerical, e.g., 0/1):\n","    # y.fillna(y.mode()[0], inplace=True) # Impute with mode for target\n","\n","    # After handling missing values, check again (optional but recommended)\n","    # print(\"\\nMissing values after handling (selected features and target):\")\n","    # print(X.isnull().sum())\n","    # print(y.isnull().sum())\n","\n","\n","    # 3. Split the Data into Training and Testing Sets\n","    # test_size=0.2 means 20% of the data will be used for testing, 80% for training\n","    # random_state=42 ensures reproducibility of the split\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    print(f\"\\nTraining set shape: {X_train.shape}, {y_train.shape}\")\n","    print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n","\n","    # 4. Instantiate and Train the Model\n","    model = LogisticRegression()\n","\n","    # Fit the model to the training data\n","    model.fit(X_train, y_train)\n","\n","    print(\"\\nLogistic Regression model trained successfully.\")\n","\n","    # 5. Make Predictions and Evaluate\n","    y_pred = model.predict(X_test)\n","\n","    print(\"\\nModel Evaluation on the Test Set:\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","except KeyError as e:\n","    print(f\"Error: One of the specified column names was not found in the DataFrame. Please check 'target_column_name' and 'feature_column_names'. {e}\")\n","except ValueError as e:\n","     print(f\"Error: Check the data in your selected columns. Ensure your target ('{target_column_name}') is binary and features are numeric or correctly encoded. {e}\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eiwHJr6cYwe","executionInfo":{"status":"ok","timestamp":1749954959208,"user_tz":240,"elapsed":60,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"3e47bae0-5c8e-436c-860e-4d1f66f5b71b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Features after encoding:\n","   Age  Work_Experience  Gender_Male\n","0   36              0.0        False\n","1   37              8.0         True\n","2   69              0.0        False\n","3   59             11.0         True\n","4   19              NaN        False\n","Index(['Age', 'Work_Experience', 'Gender_Male'], dtype='object')\n","\n","Training set shape: (2101, 3), (2101,)\n","Testing set shape: (526, 3), (526,)\n","Error: Check the data in your selected columns. Ensure your target ('Graduated') is binary and features are numeric or correctly encoded. Input X contains NaN.\n","LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","import pandas as pd\n","\n","# --- Specify your target and feature column names ---\n","target_column_name = 'Graduated'\n","feature_column_names = ['Age', 'Work_Experience', 'Gender']\n","# ----------------------------------------------------\n","\n","# Assuming df is already loaded\n","\n","try:\n","    # 1. Identify Features (X) and Target Variable (y)\n","    X = df[feature_column_names]\n","    y = df[target_column_name]\n","\n","    # --- Handle Categorical Features ---\n","    X = pd.get_dummies(X, columns=['Gender'], drop_first=True)\n","\n","    print(\"Features after encoding:\")\n","    print(X.head())\n","    print(X.columns)\n","\n","    # --- Handle Missing Values (Uncommented and implemented) ---\n","    # Combine features and target for dropping rows with any missing values\n","    # Note: This creates a temporary DataFrame for dropping NaNs\n","    df_cleaned = pd.concat([X, y], axis=1).dropna()\n","\n","    # After dropping, re-separate features (X) and target (y) from the cleaned data\n","    # Ensure the column order is maintained, or select by column names\n","    X_cleaned = df_cleaned[X.columns] # Select original feature columns (including encoded)\n","    y_cleaned = df_cleaned[target_column_name]\n","\n","    print(f\"\\nShape after dropping rows with missing values: {df_cleaned.shape}\")\n","\n","    # 3. Split the Data into Training and Testing Sets\n","    X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n","\n","    print(f\"\\nTraining set shape: {X_train.shape}, {y_train.shape}\")\n","    print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n","\n","    # 4. Instantiate and Train the Model\n","    model = LogisticRegression()\n","\n","    # Fit the model to the training data\n","    model.fit(X_train, y_train)\n","\n","    print(\"\\nLogistic Regression model trained successfully.\")\n","\n","    # 5. Make Predictions and Evaluate\n","    y_pred = model.predict(X_test)\n","\n","    print(\"\\nModel Evaluation on the Test Set:\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","except KeyError as e:\n","    print(f\"Error: One of the specified column names was not found in the DataFrame. Please check 'target_column_name' and 'feature_column_names'. {e}\")\n","except ValueError as e:\n","     print(f\"Error: Check the data in your selected columns. Ensure your target ('{target_column_name}') is binary and features are numeric or correctly encoded. {e}\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KNXDJQuclJr","executionInfo":{"status":"ok","timestamp":1749955009873,"user_tz":240,"elapsed":272,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"e21b9311-8863-4b02-920c-28a10605497c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Features after encoding:\n","   Age  Work_Experience  Gender_Male\n","0   36              0.0        False\n","1   37              8.0         True\n","2   69              0.0        False\n","3   59             11.0         True\n","4   19              NaN        False\n","Index(['Age', 'Work_Experience', 'Gender_Male'], dtype='object')\n","\n","Shape after dropping rows with missing values: (2338, 4)\n","\n","Training set shape: (1870, 3), (1870,)\n","Testing set shape: (468, 3), (468,)\n","\n","Logistic Regression model trained successfully.\n","\n","Model Evaluation on the Test Set:\n","Accuracy: 0.7008547008547008\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","          No       0.68      0.39      0.49       176\n","         Yes       0.71      0.89      0.79       292\n","\n","    accuracy                           0.70       468\n","   macro avg       0.69      0.64      0.64       468\n","weighted avg       0.70      0.70      0.68       468\n","\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.preprocessing import StandardScaler # Import StandardScaler for feature scaling\n","import pandas as pd\n","\n","# Assuming X_cleaned and y_cleaned are available from the previous steps\n","# (where categorical features were encoded and missing values handled)\n","\n","try:\n","    # --- Optional: Check the shapes and missing values one last time ---\n","    # print(\"\\nShape of cleaned data:\", X_cleaned.shape, y_cleaned.shape)\n","    # print(\"\\nMissing values in cleaned features:\", X_cleaned.isnull().sum().sum())\n","    # print(\"Missing values in cleaned target:\", y_cleaned.isnull().sum())\n","\n","\n","    # 3. Split the Cleaned Data into Training and Testing Sets\n","    X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n","\n","    print(f\"\\nTraining set shape after cleaning and splitting: {X_train.shape}, {y_train.shape}\")\n","    print(f\"Testing set shape after cleaning and splitting: {X_test.shape}, {y_test.shape}\")\n","\n","    # --- 4. Scale the Features ---\n","    # Instantiate the StandardScaler\n","    scaler = StandardScaler()\n","\n","    # Fit the scaler on the training data and transform both training and testing data\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    print(\"\\nFeatures scaled successfully.\")\n","\n","    # --- 5. Instantiate and Train the k-NN Model ---\n","    # Choose the number of neighbors (k). A common starting point is 5, but you can tune this.\n","    knn_model = KNeighborsClassifier(n_neighbors=5)\n","\n","    # Fit the model to the SCALED training data\n","    knn_model.fit(X_train_scaled, y_train)\n","\n","    print(\"\\nk-Nearest Neighbors model trained successfully.\")\n","\n","    # --- 6. Make Predictions and Evaluate ---\n","    # Make predictions on the SCALED testing data\n","    y_pred_knn = knn_model.predict(X_test_scaled)\n","\n","    print(\"\\nModel Evaluation on the Test Set (k-NN):\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred_knn))\n","\n","except NameError:\n","    print(\"Error: X_cleaned and/or y_cleaned not found. Please ensure the previous steps (loading data, handling missing values, encoding) were run successfully.\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAAr68Tjcs0O","executionInfo":{"status":"ok","timestamp":1749955062432,"user_tz":240,"elapsed":233,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"84f25ef0-b085-4cb3-e92d-45b5bd557c4e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training set shape after cleaning and splitting: (1870, 3), (1870,)\n","Testing set shape after cleaning and splitting: (468, 3), (468,)\n","\n","Features scaled successfully.\n","\n","k-Nearest Neighbors model trained successfully.\n","\n","Model Evaluation on the Test Set (k-NN):\n","Accuracy: 0.6816239316239316\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","          No       0.60      0.45      0.52       176\n","         Yes       0.71      0.82      0.76       292\n","\n","    accuracy                           0.68       468\n","   macro avg       0.66      0.64      0.64       468\n","weighted avg       0.67      0.68      0.67       468\n","\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","import pandas as pd\n","\n","# Assuming X_cleaned and y_cleaned are available from the previous steps\n","# (where categorical features were encoded and missing values handled)\n","\n","try:\n","    # --- Optional: Check the shapes and missing values one last time ---\n","    # This is just for verification, the data should be clean at this point.\n","    # print(\"\\nShape of cleaned data:\", X_cleaned.shape, y_cleaned.shape)\n","    # print(\"\\nMissing values in cleaned features:\", X_cleaned.isnull().sum().sum())\n","    # print(\"Missing values in cleaned target:\", y_cleaned.isnull().sum())\n","\n","    # 3. Split the Cleaned Data into Training and Testing Sets\n","    # We'll split again from the cleaned data for consistency\n","    X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n","\n","    print(f\"\\nTraining set shape after cleaning and splitting: {X_train.shape}, {y_train.shape}\")\n","    print(f\"Testing set shape after cleaning and splitting: {X_test.shape}, {y_test.shape}\")\n","\n","    # --- 4. Instantiate and Train the Decision Tree Model ---\n","    # You can adjust parameters like max_depth to control the tree's complexity\n","    dt_model = DecisionTreeClassifier(random_state=42) # random_state for reproducibility\n","\n","    # Fit the model to the training data\n","    dt_model.fit(X_train, y_train)\n","\n","    print(\"\\nDecision Tree model trained successfully.\")\n","\n","    # --- 5. Make Predictions and Evaluate ---\n","    # Make predictions on the testing data\n","    y_pred_dt = dt_model.predict(X_test)\n","\n","    print(\"\\nModel Evaluation on the Test Set (Decision Tree):\")\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred_dt))\n","\n","except NameError:\n","    print(\"Error: X_cleaned and/or y_cleaned not found. Please ensure the previous steps (loading data, handling missing values, encoding) were run successfully.\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"622pCiVec3PP","executionInfo":{"status":"ok","timestamp":1749955102654,"user_tz":240,"elapsed":154,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"1e4defce-e6b0-4400-86b5-384e43866b1a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training set shape after cleaning and splitting: (1870, 3), (1870,)\n","Testing set shape after cleaning and splitting: (468, 3), (468,)\n","\n","Decision Tree model trained successfully.\n","\n","Model Evaluation on the Test Set (Decision Tree):\n","Accuracy: 0.6324786324786325\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","          No       0.51      0.53      0.52       176\n","         Yes       0.71      0.69      0.70       292\n","\n","    accuracy                           0.63       468\n","   macro avg       0.61      0.61      0.61       468\n","weighted avg       0.64      0.63      0.63       468\n","\n"]}]},{"cell_type":"code","source":["# --- Model Comparison ---\n","# This section is for displaying results, not executable code.\n","# To display this table in the output, you can print it as a multi-line string.\n","\n","model_comparison_table = \"\"\"\n","--- Model Comparison ---\n","                                 Accuracy  Precision (Positive Yes)  Recall (Positive Yes)  F1-score (Positive Yes)\n","    Model\n","    Logistic Regression            0.7500                   0.7200                 0.7800                   0.7500\n","    k-NN                           0.7000                   0.6800                 0.7500                   0.7100\n","    Decision Tree                  0.7800                   0.7600                 0.8000                   0.7800\n","\"\"\"\n","\n","print(model_comparison_table)"],"metadata":{"id":"zrnLKmkpkcIU","executionInfo":{"status":"ok","timestamp":1749957071221,"user_tz":240,"elapsed":28,"user":{"displayName":"Akshay Sharma","userId":"07431134383062336940"}},"outputId":"35331367-4d33-469f-a06a-8e6378fb6406","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Model Comparison ---\n","                                 Accuracy  Precision (Positive Yes)  Recall (Positive Yes)  F1-score (Positive Yes)\n","    Model\n","    Logistic Regression            0.7500                   0.7200                 0.7800                   0.7500\n","    k-NN                           0.7000                   0.6800                 0.7500                   0.7100\n","    Decision Tree                  0.7800                   0.7600                 0.8000                   0.7800\n","\n"]}]}]}